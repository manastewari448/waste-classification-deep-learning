# -*- coding: utf-8 -*-
"""first.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TV1lpP0ykB8kZSNFlFmOB4Ac0oKFELFI
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
import zipfile
import cv2
import time
from IPython.display import display, Javascript, Image as IImage
from google.colab.output import eval_js
from base64 import b64decode
from io import BytesIO
from PIL import Image
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from sklearn.metrics import confusion_matrix, classification_report

# -----------------------------------------------------------
# Mount Google Drive
# -----------------------------------------------------------
def mount_drive():
    """Mount Google Drive with error handling."""
    try:
        drive.mount('/content/drive')
        print("Google Drive mounted successfully.")
        return True
    except Exception as e:
        print(f"Mount failed: {e}")
        return False

# -----------------------------------------------------------
# Setup dataset
# -----------------------------------------------------------
def setup_data():
    """Locate and extract the dataset.zip."""
    print("Setting up data...")
    possible_paths = [
        '/content/drive/MyDrive/Waste_Project/dataset.zip',
        '/content/drive/MyDrive/dataset.zip',
        '/content/dataset.zip',
    ]
    dataset_path = None
    for path in possible_paths:
        if os.path.exists(path):
            dataset_path = path
            print(f"Dataset found at: {path}")
            break
    if dataset_path is None:
        print("Dataset not found. Upload dataset.zip to Colab files or Google Drive.")
        return None

    extract_dir = '/content/Waste_Images'
    os.makedirs(extract_dir, exist_ok=True)
    try:
        with zipfile.ZipFile(dataset_path, 'r') as zip_ref:
            zip_ref.extractall(extract_dir)
        print("Dataset extracted successfully.")

        data_dir = None
        for root, dirs, files in os.walk(extract_dir):
            if all(c in dirs for c in ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']):
                data_dir = root
                print(f"Data directory found: {data_dir}")
                break
        if data_dir is None:
            print("Class folders not found after extraction.")
            return None
        return data_dir
    except Exception as e:
        print(f"Error extracting dataset: {e}")
        return None

# -----------------------------------------------------------
# Explore dataset
# -----------------------------------------------------------
def explore_dataset(data_dir):
    """Analyze and visualize class distribution."""
    print(f"\nExploring dataset at: {data_dir}")
    classes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]
    classes.sort()
    print(f"Found {len(classes)} classes: {classes}")

    class_counts = {}
    total_images = 0
    for class_name in classes:
        class_path = os.path.join(data_dir, class_name)
        count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
        class_counts[class_name] = count
        total_images += count

    df = pd.DataFrame(list(class_counts.items()), columns=['Class', 'Count']).sort_values('Count', ascending=False)
    print(f"\nClass Distribution:\n{df}\nTotal Images: {total_images}")

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.bar(df['Class'], df['Count'], color=['skyblue', 'salmon', 'lightgreen', 'gold', 'lightcoral', 'lightgray'])
    plt.title('Class Distribution')
    plt.xlabel('Waste Class')
    plt.ylabel('Number of Images')
    plt.xticks(rotation=45)

    plt.subplot(1, 2, 2)
    plt.pie(df['Count'], labels=df['Class'], autopct='%1.1f%%', startangle=90)
    plt.title('Class Distribution (Percentage)')

    plt.tight_layout()
    plt.show()
    return classes, class_counts

# -----------------------------------------------------------
# Create data generators
# -----------------------------------------------------------
def create_data_generators(data_dir, image_size=(224, 224), batch_size=32, validation_split=0.2):
    """Create augmented training and non-augmented validation data generators."""
    print(f"\nCreating data generators...")
    train_datagen = ImageDataGenerator(
        rescale=1./255, validation_split=validation_split, rotation_range=20,
        width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True,
        zoom_range=0.2, shear_range=0.2, fill_mode='nearest'
    )
    val_datagen = ImageDataGenerator(rescale=1./255, validation_split=validation_split)

    train_generator = train_datagen.flow_from_directory(
        data_dir, target_size=image_size, batch_size=batch_size,
        class_mode='categorical', subset='training', shuffle=True
    )
    val_generator = val_datagen.flow_from_directory(
        data_dir, target_size=image_size, batch_size=batch_size,
        class_mode='categorical', subset='validation', shuffle=False
    )
    class_labels = list(train_generator.class_indices.keys())
    num_classes = len(class_labels)
    print(f"Training samples: {train_generator.samples}, Validation samples: {val_generator.samples}")
    print(f"Number of classes: {num_classes}, Class labels: {class_labels}")
    return train_generator, val_generator, class_labels, num_classes

# -----------------------------------------------------------
# Build model
# -----------------------------------------------------------
def create_transfer_learning_model(base_model_name='VGG16', num_classes=6, input_shape=(224, 224, 3)):
    """Build VGG16-based transfer learning model with a custom classification head."""
    print(f"\nBuilding {base_model_name} transfer learning model...")
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)
    base_model.trainable = False  # Freeze base layers

    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(512, activation='relu')(x)
    x = Dropout(0.5)(x)
    x = Dense(256, activation='relu')(x)
    x = Dropout(0.3)(x)
    predictions = Dense(num_classes, activation='softmax')(x)

    model = Model(inputs=base_model.input, outputs=predictions)
    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

    print(f"Model created with {model.count_params():,} parameters.")
    print(f"Trainable parameters (initial): {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}")
    return model

# -----------------------------------------------------------
# Train model
# -----------------------------------------------------------
def train_model(model, train_generator, val_generator, epochs=20, model_name='waste_classifier'):
    """Train the model with Early Stopping, ReduceLROnPlateau, and Model Checkpoint."""
    print(f"\nTraining model for {epochs} epochs...")
    callbacks = [
        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),
        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1),
        ModelCheckpoint(f'/content/{model_name}_best.h5', monitor='val_accuracy', save_best_only=True, verbose=1)
    ]
    history = model.fit(
        train_generator,
        steps_per_epoch=train_generator.samples // train_generator.batch_size,
        epochs=epochs,
        validation_data=val_generator,
        validation_steps=val_generator.samples // val_generator.batch_size,
        callbacks=callbacks,
        verbose=1
    )
    return history

# -----------------------------------------------------------
# Fine-tune model
# -----------------------------------------------------------
def fine_tune_model(model, train_generator, val_generator, epochs=10):
    """Unfreeze and fine-tune top layers of the base model with a lower learning rate."""
    print("\nFine-tuning model...")
    # Unfreeze convolutional layers
    for layer in model.layers:
        if 'conv' in layer.name:
             layer.trainable = True

    model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])
    print(f"Fine-tuning with {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,} trainable parameters.")

    history_fine = model.fit(
        train_generator,
        steps_per_epoch=train_generator.samples // train_generator.batch_size,
        epochs=epochs,
        validation_data=val_generator,
        validation_steps=val_generator.samples // val_generator.batch_size,
        verbose=1
    )
    return history_fine

# -----------------------------------------------------------
# Evaluate model
# -----------------------------------------------------------
def plot_training_history(history, history_fine=None):
    """Plot accuracy and loss over training epochs."""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    # Plot accuracy
    axes[0, 0].plot(history.history['accuracy'], label='Training Accuracy')
    axes[0, 0].plot(history.history['val_accuracy'], label='Validation Accuracy')
    if history_fine:
        axes[0, 0].plot(history_fine.history['accuracy'], label='Fine-tuning Training')
        axes[0, 0].plot(history_fine.history['val_accuracy'], label='Fine-tuning Validation')
    axes[0, 0].set_title('Model Accuracy')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Accuracy')
    axes[0, 0].legend()
    axes[0, 0].grid(True)

    # Plot loss
    axes[0, 1].plot(history.history['loss'], label='Training Loss')
    axes[0, 1].plot(history.history['val_loss'], label='Validation Loss')
    if history_fine:
        axes[0, 1].plot(history_fine.history['loss'], label='Fine-tuning Training')
        axes[0, 1].plot(history_fine.history['val_loss'], label='Fine-tuning Validation')
    axes[0, 1].set_title('Model Loss')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('Loss')
    axes[0, 1].legend()
    axes[0, 1].grid(True)

    plt.tight_layout()
    plt.show()

def evaluate_model(model, val_generator, class_labels):
    """Generate classification report and confusion matrix."""
    print("\nEvaluating model performance...")
    val_generator.reset()
    predictions = model.predict(val_generator, verbose=1)
    y_pred = np.argmax(predictions, axis=1)
    y_true = val_generator.classes

    print("\nClassification Report:")
    print(classification_report(y_true, y_pred, target_names=class_labels))

    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

    accuracy = np.sum(y_pred == y_true) / len(y_true)
    print(f"\nOverall Accuracy: {accuracy:.4f}")
    return y_pred, y_true, accuracy

# -----------------------------------------------------------
# Model I/O and Preprocessing
# -----------------------------------------------------------
def load_waste_classifier_model():
    """Load the trained waste classification model."""
    try:
        model = load_model('/content/waste_classifier_final.h5')
        print("Model loaded successfully.")
        return model
    except:
        # Note: This load function is primarily for the direct load attempt in main()
        # The main logic handles the "not found" case gracefully.
        return None

def preprocess_image_for_prediction(img, target_size=(224, 224)):
    """Preprocess image for model prediction."""
    img_resized = cv2.resize(img, target_size)
    img_normalized = img_resized.astype(np.float32) / 255.0
    img_batch = np.expand_dims(img_normalized, axis=0)
    return img_batch

def predict_waste_class(model, img):
    """Predict waste class from image."""
    img_processed = preprocess_image_for_prediction(img)
    predictions = model.predict(img_processed, verbose=0)
    # Class labels must match the order from the generator
    class_labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']

    predicted_class_idx = np.argmax(predictions[0])
    predicted_class = class_labels[predicted_class_idx]
    confidence = predictions[0][predicted_class_idx]
    return predicted_class, confidence, predictions[0]

# -----------------------------------------------------------
# Disposal Instructions
# -----------------------------------------------------------
def get_disposal_instructions(waste_class):
    """Get disposal instructions for each waste class."""
    instructions = {
        'cardboard': {'category': 'RECYCLABLE', 'color': (0, 255, 0), 'instructions': 'Put in RECYCLING bin. Flatten boxes first.'},
        'glass': {'category': 'RECYCLABLE', 'color': (0, 255, 0), 'instructions': 'Put in RECYCLING bin. Remove caps/labels.'},
        'metal': {'category': 'RECYCLABLE', 'color': (0, 255, 0), 'instructions': 'Put in RECYCLING bin. Clean containers first.'},
        'paper': {'category': 'RECYCLABLE', 'color': (0, 255, 0), 'instructions': 'Put in RECYCLING bin. Keep dry and clean.'},
        'plastic': {'category': 'RECYCLABLE', 'color': (0, 255, 0), 'instructions': 'Put in RECYCLING bin. Check recycling number.'},
        'trash': {'category': 'NON-RECYCLABLE', 'color': (0, 0, 255), 'instructions': 'Put in GENERAL WASTE bin.'}
    }
    return instructions.get(waste_class, {'category': 'UNKNOWN', 'color': (128, 128, 128), 'instructions': 'Cannot determine category'})

def draw_prediction_on_frame(frame, waste_class, confidence, disposal_info):
    """Draw prediction results on the camera frame using OpenCV."""
    category = disposal_info['category']
    color = disposal_info['color']
    instructions = disposal_info['instructions']

    # Draw background rectangle
    cv2.rectangle(frame, (10, 10), (600, 150), (0, 0, 0), -1)
    cv2.rectangle(frame, (10, 10), (600, 150), color, 3)

    # Draw text
    cv2.putText(frame, f"CLASS: {waste_class.upper()}", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
    cv2.putText(frame, f"Confidence: {confidence:.2f}", (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    cv2.putText(frame, f"Category: {category}", (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
    cv2.putText(frame, f"Action: {instructions}", (20, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    return frame

# -----------------------------------------------------------
# Colab Webcam Utilities
# -----------------------------------------------------------
def take_photo(filename='photo.jpg', quality=0.8):
    """Capture image from Colab webcam widget and return as BGR numpy array."""
    js = Javascript('''
    async function takePhoto(quality) {
        const div = document.createElement('div');
        const video = document.createElement('video');
        video.style.display = 'block';
        const stream = await navigator.mediaDevices.getUserMedia({video: true});

        document.body.appendChild(div);
        div.appendChild(video);
        await video.play();

        // Adjust size to 224x224 to match model input and speed up transfer
        const W = 224, H = 224;
        const canvas = document.createElement('canvas');
        canvas.width = W;
        canvas.height = H;
        canvas.getContext('2d').drawImage(video, 0, 0, W, H);
        stream.getVideoTracks()[0].stop();
        div.remove();
        return canvas.toDataURL('image/jpeg', quality);
    }
    ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])

    # Convert binary data (RGB) to OpenCV image array (BGR format)
    img = np.array(Image.open(BytesIO(binary)))
    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    return img

def run_realtime_colab_camera(model):
    """Run the user-interactive, Colab-compatible waste classification demo."""
    print("Starting Colab Webcam Demo.")
    print("=" * 60)
    print("Instructions: Click 'Capture' button to take a photo. The classified image and results will display below. Press ENTER to classify another item, or type 'q' to quit.")
    print("=" * 60)

    while True:
        try:
            # Capture the frame
            frame = take_photo()

            # Predict waste class
            waste_class, confidence, _ = predict_waste_class(model, frame)
            disposal_info = get_disposal_instructions(waste_class)

            # Draw prediction on frame
            frame_with_prediction = draw_prediction_on_frame(frame, waste_class, confidence, disposal_info)

            # Save and Display the result
            filename = f'prediction_result_{int(time.time())}.jpg'
            cv2.imwrite(filename, frame_with_prediction)
            display(IImage(filename))

            print(f"CLASSIFIED: {waste_class.upper()} (Confidence: {confidence:.2%})")
            print(f"INSTRUCTION: {disposal_info['instructions']}")

            # User prompt to continue or quit
            choice = input("\nPress ENTER to capture another item, or type 'q' to quit: ").strip().lower()
            if choice == 'q':
                break

        except KeyboardInterrupt:
            print("\nCamera stopped by user.")
            break
        except Exception as e:
            print(f"Error during capture/prediction: {e}")
            break

# -----------------------------------------------------------
# Training Phase
# -----------------------------------------------------------
def train_waste_classifier():
    """Train the waste classification model."""
    print("Starting Waste Classification Training.")
    print("=" * 50)

    # Step 1: Setup data
    data_dir = setup_data()
    if data_dir is None:
        print("Training aborted.")
        return None, None

    # Step 2: Explore dataset
    classes, class_counts = explore_dataset(data_dir)

    # Step 3: Create data generators
    train_gen, val_gen, class_labels, num_classes = create_data_generators(data_dir)

    # Step 4: Build model
    model = create_transfer_learning_model('VGG16', num_classes)

    # Step 5: Train model
    print("\nStarting initial training...")
    history = train_model(model, train_gen, val_gen, epochs=10)

    # Step 6: Fine-tune
    print("\nStarting fine-tuning...")
    history_fine = fine_tune_model(model, train_gen, val_gen, epochs=5)

    # Step 7: Evaluate
    print("\nEvaluating model...")
    plot_training_history(history, history_fine)
    y_pred, y_true, accuracy = evaluate_model(model, val_gen, class_labels)

    # Step 8: Save model
    model.save('/content/waste_classifier_final.h5')
    print("Model saved successfully.")

    print(f"\nTraining completed with {accuracy:.2%} accuracy.")
    return model, class_labels

# -----------------------------------------------------------
# File Classification
# -----------------------------------------------------------
def classify_image_file(model, image_path):
    """Classify a single image file."""
    print(f"Classifying image: {image_path}")

    try:
        img = cv2.imread(image_path) # Loads image in BGR format
        if img is None:
            print(f"Could not load image: {image_path}. Check file path.")
            return

        waste_class, confidence, all_predictions = predict_waste_class(model, img)
        disposal_info = get_disposal_instructions(waste_class)

        print(f"\nClassification Results:")
        print(f"  Class: {waste_class.upper()}")
        print(f"  Confidence: {confidence:.2f}")
        print(f"  Category: {disposal_info['category']}")
        print(f"  Instructions: {disposal_info['instructions']}")

        img_with_prediction = draw_prediction_on_frame(img, waste_class, confidence, disposal_info)

        # Display image using Colab's method
        filename = f'/content/classified_result_{int(time.time())}.jpg'
        cv2.imwrite(filename, img_with_prediction)
        display(IImage(filename))

    except Exception as e:
        print(f"Error classifying image: {e}")

# -----------------------------------------------------------
# Main Application (Modified for Single Training Run)
# -----------------------------------------------------------
def main():
    """Main application function: loads model first, then prompts user for tasks."""
    mount_drive()
    model_path = '/content/waste_classifier_final.h5'
    loaded_model = None

    print("\nComplete Waste Classification Project")
    print("=" * 50)
    print("Checking for existing trained model...")

    # ATTEMPT 1: Load the saved model
    try:
        loaded_model = load_model(model_path)
        print("Trained model found and loaded successfully.")
    except Exception:
        print("No trained model found at this location. Training is required for first run.")

    # ATTEMPT 2: If model is not found, prompt to train
    if loaded_model is None:
        print("\nACTION REQUIRED:")
        print("1. Start Model Training (Must run once)")
        print("2. Exit")

        while True:
            choice = input("\nEnter your choice (1 or 2): ").strip()
            if choice == '1':
                print("\nStarting Training Phase...")
                # Train the model and overwrite loaded_model
                global_model, _ = train_waste_classifier()
                if global_model is not None:
                    loaded_model = global_model
                break
            elif choice == '2':
                print("Goodbye!")
                return
            else:
                print("Invalid choice. Please enter 1 or 2.")

    # APPLICATION LOOP: Runs only if a model (trained or loaded) is available
    while True:
        print("\nModel is ready. Choose an operation:")
        print("1. Colab Webcam classification (Start real-time demo)")
        print("2. Classify image file (from path)")
        print("3. Exit")
        print("=" * 50)

        try:
            choice = input("\nEnter your choice (1-3): ").strip()

            if choice == '1':
                run_realtime_colab_camera(loaded_model)
                # After demo exits, loop back to the menu
            elif choice == '2':
                image_path = input("Enter image file path (e.g., /content/Waste_Images/cardboard/000.jpg): ").strip()
                classify_image_file(loaded_model, image_path)
            elif choice == '3':
                print("Goodbye!")
                break
            else:
                print("Invalid choice. Please enter 1, 2, or 3.")

        except KeyboardInterrupt:
            print("\nGoodbye!")
            break
        except Exception as e:
            print(f"General Error in Main: {e}")
            break

# -----------------------------------------------------------
# Run the Project
# -----------------------------------------------------------
if __name__ == "__main__":
    print("GPU Available: ", tf.config.list_physical_devices('GPU'))
    main()

from google.colab import drive
drive.mount('/content/drive')
# mounting google drive in colab for backup and importing datasets

# Colab code to unzip
!unzip /content/drive/MyDrive/Waste_Project/dataset.zip -d /content/drive/MyDrive/Waste_Project/dataset